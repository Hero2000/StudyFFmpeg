# 播放音频

对于视频的学习初步目标已经达到了，可是到现在为止还没听到过声音，不要着急，从今天开始学习如何渲染音频。

iOS 平台用于渲染音频的技术有以下几种：

- AudioUnit
- AudioQueue
- OpenAL

本篇教程介绍如何使用 AudioUnit 渲染 FFmpeg 解码数据，其流程如下：

```
根据流信息，确定解码器，然后打开文件流（avcodec_open2） -> 读包（av_read_frame） -> 解码（avcodec_decode_audio4） -> AVFrame -> PCM -> AudioUnit 渲染
```

AudioUnit 是 iOS 实时性最好的音频处理框架，当然也可以使用较为上层的 AudioQueue，或者 OpenAL 等，后续教程会整理相应 demo 供大家参考。

# AudioUnit

The audio unit can do input as well as output. Bus 0 is used for the output side,bus 1 is used to get audio input.
            
Apple input/output audio unit sub types (iOS)

- kAudioUnitSubType_GenericOutput
- kAudioUnitSubType_VoiceProcessingIO
- kAudioUnitSubType_RemoteIO

https://blog.csdn.net/gamereborn/article/details/80232453

与视频渲染不同的是，音频不是主动送去渲染的，而是等着 AudioUnit 来要数据！要一次就给一次，需要注意的是，解出来的帧往往比要一次的要大，所以要记录下偏移量，下次从偏移量处继续给！


